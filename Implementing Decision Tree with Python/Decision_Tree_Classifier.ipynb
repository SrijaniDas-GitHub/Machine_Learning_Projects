{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Cunhm7UpTCem"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hulE4VGeT3lR"
   },
   "outputs": [],
   "source": [
    "class Decision_Tree_Classifier:\n",
    "    \"\"\"\n",
    "    Class for building decision tree classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, y, X, min_samples_split=20, max_depth=5, depth=0, node_type='root', rule=\"\", criteria=\"\"):\n",
    "        self.y, self.X = y, X\n",
    "        self.features = [col for col in self.X.columns]\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth \n",
    "        self.depth = depth if depth else 0\n",
    "        self.node_type = node_type\n",
    "        self.rule = rule \n",
    "        self.criteria=criteria\n",
    "        self.gini_or_entropy = self.get_gini_or_entropy(y1_count=None, y2_count=None, criteria=self.criteria)\n",
    "\n",
    "        # predicting y for a node\n",
    "        self.y_counts = Counter(self.y)\n",
    "        counts_sorted = list(sorted(self.y_counts.items(), key=lambda item: item[1]))\n",
    "        self.y_pred = None\n",
    "        if len(counts_sorted) > 0:\n",
    "            self.y_pred = counts_sorted[-1][0]\n",
    "\n",
    "        self.size_of_node = len(y)\n",
    "        self.left_node, self.right_node  = None, None\n",
    "        self.best_feature, self.best_threshold = None, None\n",
    "\n",
    "    @staticmethod\n",
    "    def moving_average(X, window):\n",
    "        \"\"\"\n",
    "        Calculates the moving average, that will be used as list of thresholds\n",
    "        \"\"\"\n",
    "        return np.convolve(X, np.ones(window), 'valid') / window\n",
    "\n",
    "    def get_gini_or_entropy(self, y1_count=None, y2_count=None, criteria='gini'):\n",
    "        \"\"\"\n",
    "        Returns gini or entropy of a node \n",
    "        \"\"\"\n",
    "        if not y1_count and not y2_count:\n",
    "            self.y_counts = Counter(self.y)\n",
    "            y1_count, y2_count = self.y_counts.get(0, 0), self.y_counts.get(1, 0)\n",
    "        if (y1_count + y2_count) == 0: # to avoid 'division by 0'\n",
    "            return 0.0\n",
    "        p1 = y1_count / (y1_count + y2_count)\n",
    "        p2 = y2_count / (y1_count + y2_count)\n",
    "\n",
    "        if self.criteria == 'gini':\n",
    "            gini_impurity = 1 - (p1 ** 2 + p2 ** 2)\n",
    "            return gini_impurity\n",
    "        else:\n",
    "            if p1 != 0 and p2 != 0:\n",
    "                entropy = round(-1 *(p1 * math.log(p1, 2) + p2 * math.log(p2,2)), 3)\n",
    "            elif p1 == 0 and p2 != 0:\n",
    "                entropy = round(-1 *(p2 * math.log(p2,2)), 3)\n",
    "            elif p1 != 0 and p2 ==0:\n",
    "                entropy = round(-1 *(p1 * math.log(p1, 2)), 3)\n",
    "            else:\n",
    "                entropy = 0.0\n",
    "            return abs(entropy)\n",
    "\n",
    "    def determine_best_split(self):\n",
    "        \"\"\"\n",
    "        determines the best feature and threshold for splitting a node\n",
    "        \"\"\"\n",
    "        df = self.X.copy()\n",
    "        df['y'] = self.y\n",
    "        base_gini_or_entropy = self.get_gini_or_entropy(y1_count=None, y2_count=None, criteria=self.criteria)\n",
    "\n",
    "        # Finding the split that gives the best information gain\n",
    "        max_gain, best_feature, best_threshold = 0, None, None\n",
    "\n",
    "        for feature in self.features:\n",
    "            Xdf = df.dropna().sort_values(feature)\n",
    "            thresholds = self.moving_average(Xdf[feature].unique(), 2)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                # Spliting the dataset \n",
    "                left_node_counts = Counter(Xdf[Xdf[feature]<threshold]['y']) # returns a Counter object, not same as left_node_size\n",
    "                right_node_counts = Counter(Xdf[Xdf[feature]>=threshold]['y'])\n",
    "                y0_left, y1_left, y0_right, y1_right = left_node_counts.get(0, 0), left_node_counts.get(1, 0), right_node_counts.get(0, 0), right_node_counts.get(1, 0)\n",
    "\n",
    "                # Getting gini impurities and weight of left node and right node\n",
    "                left_node_gini_or_entropy = self.get_gini_or_entropy(y1_count=y0_left, y2_count=y1_left, criteria=self.criteria)\n",
    "                right_node_gini_or_entropy = self.get_gini_or_entropy(y1_count=y0_right, y2_count=y1_right, criteria=self.criteria)\n",
    "\n",
    "                left_node_size, right_node_size = y0_left + y1_left, y0_right + y1_right\n",
    "                left_node_weight, right_node_weight = left_node_size / (left_node_size + right_node_size), right_node_size / (left_node_size + right_node_size)\n",
    "\n",
    "                # Calculating the weighted GINI impurity or entropy\n",
    "                weighted_gini_or_entropy = left_node_weight * left_node_gini_or_entropy + right_node_weight * right_node_gini_or_entropy\n",
    "                information_gain = base_gini_or_entropy - weighted_gini_or_entropy\n",
    "\n",
    "                # Checking if this is the best split so far \n",
    "                if information_gain > max_gain:\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold \n",
    "                    max_gain = information_gain # Updating maximum gain\n",
    "\n",
    "        return (best_feature, best_threshold)\n",
    "\n",
    "\n",
    "      def build_decision_tree(self):\n",
    "        \"\"\"\n",
    "        Recursive method to grow the decision tree\n",
    "        \"\"\"\n",
    "        # Making a df from the data \n",
    "        df = self.X.copy()\n",
    "        df['y'] = self.y\n",
    "\n",
    "        if (self.depth < self.max_depth) and (self.size_of_node >= self.min_samples_split):\n",
    "\n",
    "            self.best_feature, self.best_threshold = self.determine_best_split()\n",
    "\n",
    "            if self.best_feature:\n",
    "                # Getting the left and right nodes\n",
    "                left_df, right_df = df[df[self.best_feature]<=self.best_threshold].copy(), df[df[self.best_feature]>self.best_threshold].copy()\n",
    "\n",
    "                # Creating the left and right nodes\n",
    "                left_node = Decision_Tree_Classifier(\n",
    "                    left_df['y'].values.tolist(), \n",
    "                    left_df[self.features], \n",
    "                    min_samples_split=self.min_samples_split,\n",
    "                    max_depth=self.max_depth, \n",
    "                    depth=self.depth + 1, \n",
    "                    node_type='left_node',\n",
    "                    rule=f\"{self.best_feature} <= {round(self.best_threshold, 3)}\",\n",
    "                    criteria=self.criteria\n",
    "                    )\n",
    "\n",
    "                self.left_node = left_node \n",
    "                self.left_node.build_decision_tree()\n",
    "\n",
    "                right_node = Decision_Tree_Classifier(\n",
    "                    right_df['y'].values.tolist(), \n",
    "                    right_df[self.features], \n",
    "                    min_samples_split=self.min_samples_split,\n",
    "                    max_depth=self.max_depth, \n",
    "                    depth=self.depth + 1,                     \n",
    "                    node_type='right_node',\n",
    "                    rule=f\"{self.best_feature} > {round(self.best_threshold, 3)}\",\n",
    "                    criteria=self.criteria\n",
    "                    )\n",
    "\n",
    "                self.right_node = right_node\n",
    "                self.right_node.build_decision_tree()\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Batch prediction method \n",
    "        \"\"\"\n",
    "        predictions = list()\n",
    "        for val, x in X.iterrows():\n",
    "            values = dict()\n",
    "            for feature in self.features:\n",
    "                values.update({feature: x[feature]})\n",
    "\n",
    "            cur_node = self        \n",
    "            while cur_node.depth < cur_node.max_depth:\n",
    "                best_feature, best_threshold = cur_node.best_feature, cur_node.best_threshold\n",
    "                if cur_node.size_of_node < cur_node.min_samples_split:\n",
    "                    break \n",
    "                if not cur_node.best_feature:\n",
    "                    break\n",
    "                if (values[cur_node.best_feature] < cur_node.best_threshold):\n",
    "                    if self.left_node:\n",
    "                        cur_node = cur_node.left_node\n",
    "                else:\n",
    "                    if self.right_node:\n",
    "                        cur_node = cur_node.right_node\n",
    "            predictions.append(cur_node.y_pred)\n",
    "        return predictions\n",
    "\n",
    "    def print_tree(self):\n",
    "        \"\"\"\n",
    "        print decision tree\n",
    "        \"\"\"\n",
    "        padding = int(self.depth * 8)\n",
    "        space_bar = \"-\" * padding\n",
    "        if self.node_type == 'root':\n",
    "            print(\"Root Node\")\n",
    "        else:\n",
    "            print(f\"|{space_bar} Splitting Rule: {self.rule}\")\n",
    "\n",
    "        if self.criteria == 'gini':\n",
    "            print(f\"{' ' * padding}   | Gini Impurity : {round(self.gini_or_entropy, 3)}\")\n",
    "        else:\n",
    "            print(f\"{' ' * padding}   | Entropy : {round(self.gini_or_entropy, 3)}\")\n",
    "        print(f\"{' ' * padding}   | Class distribution : {dict(self.y_counts)}\")\n",
    "        print(f\"{' ' * padding}   | Predicted value : {self.y_pred}\")\n",
    "\n",
    "        if self.left_node: \n",
    "            self.left_node.print_tree()\n",
    "\n",
    "        if self.right_node:\n",
    "            self.right_node.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDBb6jAGf1qS"
   },
   "source": [
    "# Decision Tree for Odd and Even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "id": "uoYh0fW_e7Ng",
    "outputId": "b4328cc5-6a1c-4220-de9b-e530d8427c1b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x3</th>\n",
       "      <th>x2</th>\n",
       "      <th>x1</th>\n",
       "      <th>x0</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x3  x2  x1  x0  y\n",
       "0    0   0   0   0  0\n",
       "1    0   0   0   1  1\n",
       "2    0   0   1   0  0\n",
       "3    0   0   1   1  1\n",
       "4    0   1   0   0  0\n",
       "5    0   1   0   1  1\n",
       "6    0   1   1   0  0\n",
       "7    0   1   1   1  1\n",
       "8    1   0   0   0  0\n",
       "9    1   0   0   1  1\n",
       "10   1   0   1   0  0\n",
       "11   1   0   1   1  1\n",
       "12   1   1   0   0  0\n",
       "13   1   1   0   1  1\n",
       "14   1   1   1   0  0\n",
       "15   1   1   1   1  1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data for classification \n",
    "data_2 =  pd.read_excel(\"/content/odd_even.xlsx\")\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oNB8diA8fABm"
   },
   "outputs": [],
   "source": [
    "X = data_2.drop(\"y\", axis=1)\n",
    "y = data_2[\"y\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbRXbCHAfRlu",
    "outputId": "8dfa7414-e206-4306-f57c-ff84671157e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Node\n",
      "   | Entropy : 1.0\n",
      "   | Class distribution : {0: 6, 1: 6}\n",
      "   | Predicted value : 1\n",
      "|-------- Splitting Rule: x0 <= 0.5\n",
      "           | Entropy : 0.0\n",
      "           | Class distribution : {0: 6}\n",
      "           | Predicted value : 0\n",
      "|-------- Splitting Rule: x0 > 0.5\n",
      "           | Entropy : 0.0\n",
      "           | Class distribution : {1: 6}\n",
      "           | Predicted value : 1\n"
     ]
    }
   ],
   "source": [
    "dtree_entropy = Decision_Tree_Classifier(y_train, X_train, min_samples_split=2, criteria='entropy')\n",
    "\n",
    "dtree_entropy.build_decision_tree()\n",
    "dtree_entropy.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NW6adqacfbcs",
    "outputId": "8ca0b318-93cd-4087-9a34-3fd153eb99d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy: 1.0\n",
      "The test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "y_pred_test = dtree_entropy.predict(X_test)\n",
    "y_pred_train = dtree_entropy.predict(X_train)\n",
    "\n",
    "# Measurring accuracy\n",
    "print(f\"The train accuracy: {round(accuracy_score(y_train, y_pred_train),3)}\")\n",
    "print(f\"The test accuracy: {round(accuracy_score(y_test, y_pred_test),3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "XHt1L8EdrNGs",
    "outputId": "ebc9a47f-ce56-4cb2-f4b2-91e9523224ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5   ...     52     53     54   55    56  57\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  ...  0.000  0.000  3.756   61   278   1\n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  ...  0.180  0.048  5.114  101  1028   1\n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  ...  0.184  0.010  9.821  485  2259   1\n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191   1\n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  ...  0.000  0.000  3.537   40   191   1\n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data for classification \n",
    "data =  pd.read_excel(\"/content/spam_data.xls\", header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0w-9yitlOCpa"
   },
   "outputs": [],
   "source": [
    "column_names = dict()\n",
    "for i,col in enumerate(data.columns):\n",
    "  column_names[i] = \"feature_\" + str(i+1)\n",
    "data.rename(columns=column_names, inplace=True)\n",
    "\n",
    "X = data.drop(\"feature_58\", axis=1)\n",
    "y = data[\"feature_58\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=47)\n",
    "\n",
    "print(y_train.sum()/len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3PZKATsN0Zb"
   },
   "source": [
    "# Decision Tree with Gini Impurity as splitting Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rdX5gMqyaLT",
    "outputId": "ed633435-6ed1-400b-8ebb-f8251d27f559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Node\n",
      "   | Gini Impurity : 0.478\n",
      "   | Class distribution : {1: 1450, 0: 2230}\n",
      "   | Predicted value : 0\n",
      "|-------- Splitting Rule: feature_52 <= 0.08\n",
      "           | Gini Impurity : 0.267\n",
      "           | Class distribution : {1: 338, 0: 1796}\n",
      "           | Predicted value : 0\n",
      "|---------------- Splitting Rule: feature_7 <= 0.045\n",
      "                   | Gini Impurity : 0.191\n",
      "                   | Class distribution : {0: 1775, 1: 213}\n",
      "                   | Predicted value : 0\n",
      "|------------------------ Splitting Rule: feature_24 <= 0.01\n",
      "                           | Gini Impurity : 0.15\n",
      "                           | Class distribution : {0: 1742, 1: 155}\n",
      "                           | Predicted value : 0\n",
      "|-------------------------------- Splitting Rule: feature_16 <= 0.195\n",
      "                                   | Gini Impurity : 0.117\n",
      "                                   | Class distribution : {0: 1662, 1: 111}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_53 <= 0.174\n",
      "                                           | Gini Impurity : 0.103\n",
      "                                           | Class distribution : {0: 1647, 1: 95}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_53 > 0.174\n",
      "                                           | Gini Impurity : 0.499\n",
      "                                           | Class distribution : {0: 15, 1: 16}\n",
      "                                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_16 > 0.195\n",
      "                                   | Gini Impurity : 0.458\n",
      "                                   | Class distribution : {0: 80, 1: 44}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_5 <= 1.095\n",
      "                                           | Gini Impurity : 0.372\n",
      "                                           | Class distribution : {0: 73, 1: 24}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_5 > 1.095\n",
      "                                           | Gini Impurity : 0.384\n",
      "                                           | Class distribution : {1: 20, 0: 7}\n",
      "                                           | Predicted value : 1\n",
      "|------------------------ Splitting Rule: feature_24 > 0.01\n",
      "                           | Gini Impurity : 0.462\n",
      "                           | Class distribution : {1: 58, 0: 33}\n",
      "                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_53 <= 0.056\n",
      "                                   | Gini Impurity : 0.444\n",
      "                                   | Class distribution : {0: 26, 1: 13}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_55 <= 4.186\n",
      "                                           | Gini Impurity : 0.278\n",
      "                                           | Class distribution : {0: 25, 1: 5}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_55 > 4.186\n",
      "                                           | Gini Impurity : 0.198\n",
      "                                           | Class distribution : {0: 1, 1: 8}\n",
      "                                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_53 > 0.056\n",
      "                                   | Gini Impurity : 0.233\n",
      "                                   | Class distribution : {1: 45, 0: 7}\n",
      "                                   | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_21 <= 0.635\n",
      "                                           | Gini Impurity : 0.5\n",
      "                                           | Class distribution : {1: 5, 0: 5}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_21 > 0.635\n",
      "                                           | Gini Impurity : 0.091\n",
      "                                           | Class distribution : {1: 40, 0: 2}\n",
      "                                           | Predicted value : 1\n",
      "|---------------- Splitting Rule: feature_7 > 0.045\n",
      "                   | Gini Impurity : 0.246\n",
      "                   | Class distribution : {1: 125, 0: 21}\n",
      "                   | Predicted value : 1\n",
      "|------------------------ Splitting Rule: feature_27 <= 0.08\n",
      "                           | Gini Impurity : 0.149\n",
      "                           | Class distribution : {1: 125, 0: 11}\n",
      "                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_25 <= 0.15\n",
      "                                   | Gini Impurity : 0.09\n",
      "                                   | Class distribution : {1: 121, 0: 6}\n",
      "                                   | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_8 <= 2.13\n",
      "                                           | Gini Impurity : 0.076\n",
      "                                           | Class distribution : {1: 121, 0: 5}\n",
      "                                           | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_8 > 2.13\n",
      "                                           | Gini Impurity : 0.0\n",
      "                                           | Class distribution : {0: 1}\n",
      "                                           | Predicted value : 0\n",
      "|-------------------------------- Splitting Rule: feature_25 > 0.15\n",
      "                                   | Gini Impurity : 0.494\n",
      "                                   | Class distribution : {0: 5, 1: 4}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_5 <= 0.43\n",
      "                                           | Gini Impurity : 0.0\n",
      "                                           | Class distribution : {0: 4}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_5 > 0.43\n",
      "                                           | Gini Impurity : 0.32\n",
      "                                           | Class distribution : {1: 4, 0: 1}\n",
      "                                           | Predicted value : 1\n",
      "|------------------------ Splitting Rule: feature_27 > 0.08\n",
      "                           | Gini Impurity : 0.0\n",
      "                           | Class distribution : {0: 10}\n",
      "                           | Predicted value : 0\n",
      "|-------- Splitting Rule: feature_52 > 0.08\n",
      "           | Gini Impurity : 0.404\n",
      "           | Class distribution : {1: 1112, 0: 434}\n",
      "           | Predicted value : 1\n",
      "|---------------- Splitting Rule: feature_55 <= 2.312\n",
      "                   | Gini Impurity : 0.473\n",
      "                   | Class distribution : {0: 320, 1: 199}\n",
      "                   | Predicted value : 0\n",
      "|------------------------ Splitting Rule: feature_16 <= 0.295\n",
      "                           | Gini Impurity : 0.362\n",
      "                           | Class distribution : {0: 295, 1: 92}\n",
      "                           | Predicted value : 0\n",
      "|-------------------------------- Splitting Rule: feature_7 <= 0.07\n",
      "                                   | Gini Impurity : 0.271\n",
      "                                   | Class distribution : {0: 290, 1: 56}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_8 <= 0.535\n",
      "                                           | Gini Impurity : 0.222\n",
      "                                           | Class distribution : {0: 289, 1: 42}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_8 > 0.535\n",
      "                                           | Gini Impurity : 0.124\n",
      "                                           | Class distribution : {1: 14, 0: 1}\n",
      "                                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_7 > 0.07\n",
      "                                   | Gini Impurity : 0.214\n",
      "                                   | Class distribution : {1: 36, 0: 5}\n",
      "                                   | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_46 <= 0.115\n",
      "                                           | Gini Impurity : 0.1\n",
      "                                           | Class distribution : {1: 36, 0: 2}\n",
      "                                           | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_46 > 0.115\n",
      "                                           | Gini Impurity : 0.0\n",
      "                                           | Class distribution : {0: 3}\n",
      "                                           | Predicted value : 0\n",
      "|------------------------ Splitting Rule: feature_16 > 0.295\n",
      "                           | Gini Impurity : 0.307\n",
      "                           | Class distribution : {1: 107, 0: 25}\n",
      "                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_27 <= 0.19\n",
      "                                   | Gini Impurity : 0.274\n",
      "                                   | Class distribution : {1: 107, 0: 21}\n",
      "                                   | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_7 <= 0.1\n",
      "                                           | Gini Impurity : 0.369\n",
      "                                           | Class distribution : {1: 65, 0: 21}\n",
      "                                           | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_7 > 0.1\n",
      "                                           | Gini Impurity : 0.0\n",
      "                                           | Class distribution : {1: 42}\n",
      "                                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_27 > 0.19\n",
      "                                   | Gini Impurity : 0.0\n",
      "                                   | Class distribution : {0: 4}\n",
      "                                   | Predicted value : 0\n",
      "|---------------- Splitting Rule: feature_55 > 2.312\n",
      "                   | Gini Impurity : 0.197\n",
      "                   | Class distribution : {1: 913, 0: 114}\n",
      "                   | Predicted value : 1\n",
      "|------------------------ Splitting Rule: feature_25 <= 0.39\n",
      "                           | Gini Impurity : 0.143\n",
      "                           | Class distribution : {1: 906, 0: 76}\n",
      "                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_42 <= 0.515\n",
      "                                   | Gini Impurity : 0.122\n",
      "                                   | Class distribution : {1: 906, 0: 63}\n",
      "                                   | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_46 <= 0.59\n",
      "                                           | Gini Impurity : 0.108\n",
      "                                           | Class distribution : {1: 906, 0: 55}\n",
      "                                           | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_46 > 0.59\n",
      "                                           | Gini Impurity : 0.0\n",
      "                                           | Class distribution : {0: 8}\n",
      "                                           | Predicted value : 0\n",
      "|-------------------------------- Splitting Rule: feature_42 > 0.515\n",
      "                                   | Gini Impurity : 0.0\n",
      "                                   | Class distribution : {0: 13}\n",
      "                                   | Predicted value : 0\n",
      "|------------------------ Splitting Rule: feature_25 > 0.39\n",
      "                           | Gini Impurity : 0.263\n",
      "                           | Class distribution : {0: 38, 1: 7}\n",
      "                           | Predicted value : 0\n",
      "|-------------------------------- Splitting Rule: feature_16 <= 0.74\n",
      "                                   | Gini Impurity : 0.05\n",
      "                                   | Class distribution : {0: 38, 1: 1}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_7 <= 0.415\n",
      "                                           | Gini Impurity : 0.0\n",
      "                                           | Class distribution : {0: 38}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_7 > 0.415\n",
      "                                           | Gini Impurity : 0.0\n",
      "                                           | Class distribution : {1: 1}\n",
      "                                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_16 > 0.74\n",
      "                                   | Gini Impurity : 0.0\n",
      "                                   | Class distribution : {1: 6}\n",
      "                                   | Predicted value : 1\n"
     ]
    }
   ],
   "source": [
    "dtree_gini = Decision_Tree_Classifier(y_train, X_train, min_samples_split=2, max_depth=5, criteria='gini')\n",
    "\n",
    "dtree_gini.build_decision_tree()\n",
    "dtree_gini.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBU0eJSe1Jnb",
    "outputId": "493f3ddb-8399-472e-ad79-33bffc7eae17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy: 0.924\n",
      "The test accuracy: 0.924\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "y_pred_test = dtree_gini.predict(X_test)\n",
    "y_pred_train = dtree_gini.predict(X_train)\n",
    "\n",
    "# Measurring accuracy\n",
    "print(f\"The train accuracy: {round(accuracy_score(y_train, y_pred_train),3)}\")\n",
    "print(f\"The test accuracy: {round(accuracy_score(y_test, y_pred_test),3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAd6fmH5Noln"
   },
   "source": [
    "# Decision Tree with Entropy as splitting Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NV6icwnlpdMJ",
    "outputId": "0cbab015-18b2-4a13-9cce-3fb219dc54e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Node\n",
      "   | Entropy : 0.967\n",
      "   | Class distribution : {1: 1450, 0: 2230}\n",
      "   | Predicted value : 0\n",
      "|-------- Splitting Rule: feature_52 <= 0.08\n",
      "           | Entropy : 0.63\n",
      "           | Class distribution : {1: 338, 0: 1796}\n",
      "           | Predicted value : 0\n",
      "|---------------- Splitting Rule: feature_7 <= 0.045\n",
      "                   | Entropy : 0.491\n",
      "                   | Class distribution : {0: 1775, 1: 213}\n",
      "                   | Predicted value : 0\n",
      "|------------------------ Splitting Rule: feature_53 <= 0.09\n",
      "                           | Entropy : 0.403\n",
      "                           | Class distribution : {0: 1734, 1: 151}\n",
      "                           | Predicted value : 0\n",
      "|-------------------------------- Splitting Rule: feature_25 <= 0.135\n",
      "                                   | Entropy : 0.53\n",
      "                                   | Class distribution : {0: 1074, 1: 147}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_56 <= 9.5\n",
      "                                           | Entropy : 0.277\n",
      "                                           | Class distribution : {0: 737, 1: 37}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_56 > 9.5\n",
      "                                           | Entropy : 0.805\n",
      "                                           | Class distribution : {0: 337, 1: 110}\n",
      "                                           | Predicted value : 0\n",
      "|-------------------------------- Splitting Rule: feature_25 > 0.135\n",
      "                                   | Entropy : 0.053\n",
      "                                   | Class distribution : {0: 660, 1: 4}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_11 <= 0.985\n",
      "                                           | Entropy : 0.03\n",
      "                                           | Class distribution : {0: 660, 1: 2}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_11 > 0.985\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {1: 2}\n",
      "                                           | Predicted value : 1\n",
      "|------------------------ Splitting Rule: feature_53 > 0.09\n",
      "                           | Entropy : 0.97\n",
      "                           | Class distribution : {1: 62, 0: 41}\n",
      "                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_25 <= 0.24\n",
      "                                   | Entropy : 0.83\n",
      "                                   | Class distribution : {1: 62, 0: 22}\n",
      "                                   | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_56 <= 7.0\n",
      "                                           | Entropy : 0.469\n",
      "                                           | Class distribution : {0: 9, 1: 1}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_56 > 7.0\n",
      "                                           | Entropy : 0.671\n",
      "                                           | Class distribution : {1: 61, 0: 13}\n",
      "                                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_25 > 0.24\n",
      "                                   | Entropy : 0.0\n",
      "                                   | Class distribution : {0: 19}\n",
      "                                   | Predicted value : 0\n",
      "|---------------- Splitting Rule: feature_7 > 0.045\n",
      "                   | Entropy : 0.594\n",
      "                   | Class distribution : {1: 125, 0: 21}\n",
      "                   | Predicted value : 1\n",
      "|------------------------ Splitting Rule: feature_27 <= 0.08\n",
      "                           | Entropy : 0.405\n",
      "                           | Class distribution : {1: 125, 0: 11}\n",
      "                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_25 <= 0.15\n",
      "                                   | Entropy : 0.275\n",
      "                                   | Class distribution : {1: 121, 0: 6}\n",
      "                                   | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_5 <= 0.295\n",
      "                                           | Entropy : 0.551\n",
      "                                           | Class distribution : {1: 41, 0: 6}\n",
      "                                           | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_5 > 0.295\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {1: 80}\n",
      "                                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_25 > 0.15\n",
      "                                   | Entropy : 0.991\n",
      "                                   | Class distribution : {0: 5, 1: 4}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_5 <= 0.43\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {0: 4}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_5 > 0.43\n",
      "                                           | Entropy : 0.722\n",
      "                                           | Class distribution : {1: 4, 0: 1}\n",
      "                                           | Predicted value : 1\n",
      "|------------------------ Splitting Rule: feature_27 > 0.08\n",
      "                           | Entropy : 0.0\n",
      "                           | Class distribution : {0: 10}\n",
      "                           | Predicted value : 0\n",
      "|-------- Splitting Rule: feature_52 > 0.08\n",
      "           | Entropy : 0.856\n",
      "           | Class distribution : {1: 1112, 0: 434}\n",
      "           | Predicted value : 1\n",
      "|---------------- Splitting Rule: feature_55 <= 2.754\n",
      "                   | Entropy : 0.992\n",
      "                   | Class distribution : {0: 367, 1: 296}\n",
      "                   | Predicted value : 0\n",
      "|------------------------ Splitting Rule: feature_7 <= 0.045\n",
      "                           | Entropy : 0.915\n",
      "                           | Class distribution : {0: 362, 1: 178}\n",
      "                           | Predicted value : 0\n",
      "|-------------------------------- Splitting Rule: feature_53 <= 0.008\n",
      "                                   | Entropy : 0.755\n",
      "                                   | Class distribution : {1: 94, 0: 339}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_16 <= 0.195\n",
      "                                           | Entropy : 0.581\n",
      "                                           | Class distribution : {1: 50, 0: 310}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_16 > 0.195\n",
      "                                           | Entropy : 0.969\n",
      "                                           | Class distribution : {0: 29, 1: 44}\n",
      "                                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_53 > 0.008\n",
      "                                   | Entropy : 0.751\n",
      "                                   | Class distribution : {0: 23, 1: 84}\n",
      "                                   | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_21 <= 0.4\n",
      "                                           | Entropy : 0.971\n",
      "                                           | Class distribution : {1: 10, 0: 15}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_21 > 0.4\n",
      "                                           | Entropy : 0.461\n",
      "                                           | Class distribution : {0: 8, 1: 74}\n",
      "                                           | Predicted value : 1\n",
      "|------------------------ Splitting Rule: feature_7 > 0.045\n",
      "                           | Entropy : 0.245\n",
      "                           | Class distribution : {1: 118, 0: 5}\n",
      "                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_46 <= 0.115\n",
      "                                   | Entropy : 0.123\n",
      "                                   | Class distribution : {1: 117, 0: 2}\n",
      "                                   | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_30 <= 0.615\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {1: 117}\n",
      "                                           | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_30 > 0.615\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {0: 2}\n",
      "                                           | Predicted value : 0\n",
      "|-------------------------------- Splitting Rule: feature_46 > 0.115\n",
      "                                   | Entropy : 0.811\n",
      "                                   | Class distribution : {0: 3, 1: 1}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_5 <= 1.145\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {0: 3}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_5 > 1.145\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {1: 1}\n",
      "                                           | Predicted value : 1\n",
      "|---------------- Splitting Rule: feature_55 > 2.754\n",
      "                   | Entropy : 0.387\n",
      "                   | Class distribution : {1: 816, 0: 67}\n",
      "                   | Predicted value : 1\n",
      "|------------------------ Splitting Rule: feature_53 <= 0.006\n",
      "                           | Entropy : 0.678\n",
      "                           | Class distribution : {1: 261, 0: 57}\n",
      "                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_25 <= 0.105\n",
      "                                   | Entropy : 0.553\n",
      "                                   | Class distribution : {1: 258, 0: 38}\n",
      "                                   | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_42 <= 0.615\n",
      "                                           | Entropy : 0.492\n",
      "                                           | Class distribution : {1: 258, 0: 31}\n",
      "                                           | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_42 > 0.615\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {0: 7}\n",
      "                                           | Predicted value : 0\n",
      "|-------------------------------- Splitting Rule: feature_25 > 0.105\n",
      "                                   | Entropy : 0.575\n",
      "                                   | Class distribution : {0: 19, 1: 3}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_16 <= 0.74\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {0: 19}\n",
      "                                           | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_16 > 0.74\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {1: 3}\n",
      "                                           | Predicted value : 1\n",
      "|------------------------ Splitting Rule: feature_53 > 0.006\n",
      "                           | Entropy : 0.128\n",
      "                           | Class distribution : {1: 555, 0: 10}\n",
      "                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_25 <= 1.195\n",
      "                                   | Entropy : 0.097\n",
      "                                   | Class distribution : {1: 554, 0: 7}\n",
      "                                   | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_46 <= 0.18\n",
      "                                           | Entropy : 0.074\n",
      "                                           | Class distribution : {1: 551, 0: 5}\n",
      "                                           | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_46 > 0.18\n",
      "                                           | Entropy : 0.971\n",
      "                                           | Class distribution : {0: 2, 1: 3}\n",
      "                                           | Predicted value : 1\n",
      "|-------------------------------- Splitting Rule: feature_25 > 1.195\n",
      "                                   | Entropy : 0.811\n",
      "                                   | Class distribution : {0: 3, 1: 1}\n",
      "                                   | Predicted value : 0\n",
      "|---------------------------------------- Splitting Rule: feature_3 <= 0.165\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {1: 1}\n",
      "                                           | Predicted value : 1\n",
      "|---------------------------------------- Splitting Rule: feature_3 > 0.165\n",
      "                                           | Entropy : 0.0\n",
      "                                           | Class distribution : {0: 3}\n",
      "                                           | Predicted value : 0\n"
     ]
    }
   ],
   "source": [
    "dtree_entropy = Decision_Tree_Classifier(y_train, X_train, min_samples_split=2, criteria='entropy')\n",
    "\n",
    "dtree_entropy.build_decision_tree()\n",
    "dtree_entropy.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24Mzdo8NNivq",
    "outputId": "5202a385-b7cf-47f8-fe45-9d3e326957de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train accuracy: 0.917\n",
      "The test accuracy: 0.922\n"
     ]
    }
   ],
   "source": [
    "# Making predictions\n",
    "y_pred_test = dtree_entropy.predict(X_test)\n",
    "y_pred_train = dtree_entropy.predict(X_train)\n",
    "\n",
    "# Measurring accuracy\n",
    "print(f\"The train accuracy: {round(accuracy_score(y_train, y_pred_train),3)}\")\n",
    "print(f\"The test accuracy: {round(accuracy_score(y_test, y_pred_test),3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FS--K4XmfmMa"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Decision_Tree_with_gini_from_Scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
